{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad2cea1-42cb-47a4-bc6f-205d1de37fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memasukan liblary yang dipakai \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e4e60e-05f8-4a3c-b3fc-f18e617ccb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
       "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
       "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
       "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
       "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
       "\n",
       "   ca  thal  condition  \n",
       "0   1     0          0  \n",
       "1   2     0          0  \n",
       "2   0     0          0  \n",
       "3   1     0          1  \n",
       "4   0     0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membaca dataset dari file CSV menggunakan Pandas\n",
    "df = pd.read_csv(\"heart_cleveland_upload.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16024810-438a-499b-b1d3-e0e81f0c5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengubah data int ke fload / menyamakan seluruh data ke float \n",
    "df = df.astype({\n",
    "    'age': float,\n",
    "    'sex': float,\n",
    "    'cp': float,\n",
    "    'trestbps': float,\n",
    "    'chol': float,\n",
    "    'fbs': float,\n",
    "    'restecg': float,\n",
    "    'thalach': float,\n",
    "    'exang': float,\n",
    "    'oldpeak': float,\n",
    "    'slope': float,\n",
    "    'ca': float,\n",
    "    'thal': float,\n",
    "    'condition': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeb0509-b580-4266-b23e-1a7501b65e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex          float64\n",
       "cp           float64\n",
       "trestbps     float64\n",
       "chol         float64\n",
       "fbs          float64\n",
       "restecg      float64\n",
       "thalach      float64\n",
       "exang        float64\n",
       "oldpeak      float64\n",
       "slope        float64\n",
       "ca           float64\n",
       "thal         float64\n",
       "condition    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #cek data tipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c19e25-c42a-48d9-9af4-03833b2aa2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #cek jumlah kolom,baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfac6837-47ce-4aaa-83ff-87a1e84bb454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memasukan data input dan output kedalam variable untuk training\n",
    "\n",
    "X = df.drop(\"condition\", axis=1).values  #input dari semua tabel dari df, kecuali coloum \"condition\"\n",
    "y = df[\"condition\"].values               #output hanya value dari coloum \"condition\"\n",
    "\n",
    "# Memasukan data input dan output kedalam variable untuk testing\n",
    "X_test = X\n",
    "y_test = y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86963608-24fa-4f91-b4b3-97f8455efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan perangkat yang akan digunakan (CPU atau CUDA)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Definisikan model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  #input 13\n",
    "        self.fc2 = nn.Linear(128, 64)          #hidden layer 1 memiliki 128 neuron\n",
    "        self.fc3 = nn.Linear(64, 32)           #hidden layer 2 memiliki 64 neuron\n",
    "        self.fc4 = nn.Linear(32, 1)            #output 1\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Membuat instance model\n",
    "input_size = 13  # Sesuaikan dengan jumlah atribut\n",
    "model = ANN(input_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665b168e-b4bc-4c17-b2c6-7c9e74f8a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/297], Loss: 6.0742\n",
      "Epoch [2/297], Loss: 0.6178\n",
      "Epoch [3/297], Loss: 1.4695\n",
      "Epoch [4/297], Loss: 0.4310\n",
      "Epoch [5/297], Loss: 1.4822\n",
      "Epoch [6/297], Loss: 0.4287\n",
      "Epoch [7/297], Loss: 1.1421\n",
      "Epoch [8/297], Loss: 0.4993\n",
      "Epoch [9/297], Loss: 0.7132\n",
      "Epoch [10/297], Loss: 0.6668\n",
      "Epoch [11/297], Loss: 0.6005\n",
      "Epoch [12/297], Loss: 0.7328\n",
      "Epoch [13/297], Loss: 0.5907\n",
      "Epoch [14/297], Loss: 0.7296\n",
      "Epoch [15/297], Loss: 0.6044\n",
      "Epoch [16/297], Loss: 0.7162\n",
      "Epoch [17/297], Loss: 0.6240\n",
      "Epoch [18/297], Loss: 0.7045\n",
      "Epoch [19/297], Loss: 0.6422\n",
      "Epoch [20/297], Loss: 0.6911\n",
      "Epoch [21/297], Loss: 0.6532\n",
      "Epoch [22/297], Loss: 0.6752\n",
      "Epoch [23/297], Loss: 0.6560\n",
      "Epoch [24/297], Loss: 0.6611\n",
      "Epoch [25/297], Loss: 0.6552\n",
      "Epoch [26/297], Loss: 0.6517\n",
      "Epoch [27/297], Loss: 0.6535\n",
      "Epoch [28/297], Loss: 0.6462\n",
      "Epoch [29/297], Loss: 0.6506\n",
      "Epoch [30/297], Loss: 0.6424\n",
      "Epoch [31/297], Loss: 0.6459\n",
      "Epoch [32/297], Loss: 0.6387\n",
      "Epoch [33/297], Loss: 0.6401\n",
      "Epoch [34/297], Loss: 0.6348\n",
      "Epoch [35/297], Loss: 0.6339\n",
      "Epoch [36/297], Loss: 0.6305\n",
      "Epoch [37/297], Loss: 0.6278\n",
      "Epoch [38/297], Loss: 0.6253\n",
      "Epoch [39/297], Loss: 0.6217\n",
      "Epoch [40/297], Loss: 0.6195\n",
      "Epoch [41/297], Loss: 0.6157\n",
      "Epoch [42/297], Loss: 0.6133\n",
      "Epoch [43/297], Loss: 0.6098\n",
      "Epoch [44/297], Loss: 0.6071\n",
      "Epoch [45/297], Loss: 0.6039\n",
      "Epoch [46/297], Loss: 0.6008\n",
      "Epoch [47/297], Loss: 0.5978\n",
      "Epoch [48/297], Loss: 0.5945\n",
      "Epoch [49/297], Loss: 0.5914\n",
      "Epoch [50/297], Loss: 0.5881\n",
      "Epoch [51/297], Loss: 0.5850\n",
      "Epoch [52/297], Loss: 0.5817\n",
      "Epoch [53/297], Loss: 0.5785\n",
      "Epoch [54/297], Loss: 0.5752\n",
      "Epoch [55/297], Loss: 0.5719\n",
      "Epoch [56/297], Loss: 0.5686\n",
      "Epoch [57/297], Loss: 0.5653\n",
      "Epoch [58/297], Loss: 0.5620\n",
      "Epoch [59/297], Loss: 0.5586\n",
      "Epoch [60/297], Loss: 0.5552\n",
      "Epoch [61/297], Loss: 0.5519\n",
      "Epoch [62/297], Loss: 0.5485\n",
      "Epoch [63/297], Loss: 0.5451\n",
      "Epoch [64/297], Loss: 0.5416\n",
      "Epoch [65/297], Loss: 0.5382\n",
      "Epoch [66/297], Loss: 0.5347\n",
      "Epoch [67/297], Loss: 0.5313\n",
      "Epoch [68/297], Loss: 0.5278\n",
      "Epoch [69/297], Loss: 0.5243\n",
      "Epoch [70/297], Loss: 0.5208\n",
      "Epoch [71/297], Loss: 0.5173\n",
      "Epoch [72/297], Loss: 0.5138\n",
      "Epoch [73/297], Loss: 0.5103\n",
      "Epoch [74/297], Loss: 0.5068\n",
      "Epoch [75/297], Loss: 0.5032\n",
      "Epoch [76/297], Loss: 0.4997\n",
      "Epoch [77/297], Loss: 0.4962\n",
      "Epoch [78/297], Loss: 0.4926\n",
      "Epoch [79/297], Loss: 0.4891\n",
      "Epoch [80/297], Loss: 0.4856\n",
      "Epoch [81/297], Loss: 0.4821\n",
      "Epoch [82/297], Loss: 0.4786\n",
      "Epoch [83/297], Loss: 0.4751\n",
      "Epoch [84/297], Loss: 0.4716\n",
      "Epoch [85/297], Loss: 0.4681\n",
      "Epoch [86/297], Loss: 0.4647\n",
      "Epoch [87/297], Loss: 0.4612\n",
      "Epoch [88/297], Loss: 0.4578\n",
      "Epoch [89/297], Loss: 0.4544\n",
      "Epoch [90/297], Loss: 0.4511\n",
      "Epoch [91/297], Loss: 0.4477\n",
      "Epoch [92/297], Loss: 0.4445\n",
      "Epoch [93/297], Loss: 0.4412\n",
      "Epoch [94/297], Loss: 0.4380\n",
      "Epoch [95/297], Loss: 0.4348\n",
      "Epoch [96/297], Loss: 0.4317\n",
      "Epoch [97/297], Loss: 0.4286\n",
      "Epoch [98/297], Loss: 0.4255\n",
      "Epoch [99/297], Loss: 0.4225\n",
      "Epoch [100/297], Loss: 0.4196\n",
      "Epoch [101/297], Loss: 0.4167\n",
      "Epoch [102/297], Loss: 0.4138\n",
      "Epoch [103/297], Loss: 0.4110\n",
      "Epoch [104/297], Loss: 0.4083\n",
      "Epoch [105/297], Loss: 0.4056\n",
      "Epoch [106/297], Loss: 0.4030\n",
      "Epoch [107/297], Loss: 0.4004\n",
      "Epoch [108/297], Loss: 0.3979\n",
      "Epoch [109/297], Loss: 0.3955\n",
      "Epoch [110/297], Loss: 0.3931\n",
      "Epoch [111/297], Loss: 0.3908\n",
      "Epoch [112/297], Loss: 0.3885\n",
      "Epoch [113/297], Loss: 0.3863\n",
      "Epoch [114/297], Loss: 0.3842\n",
      "Epoch [115/297], Loss: 0.3821\n",
      "Epoch [116/297], Loss: 0.3800\n",
      "Epoch [117/297], Loss: 0.3780\n",
      "Epoch [118/297], Loss: 0.3761\n",
      "Epoch [119/297], Loss: 0.3742\n",
      "Epoch [120/297], Loss: 0.3724\n",
      "Epoch [121/297], Loss: 0.3706\n",
      "Epoch [122/297], Loss: 0.3689\n",
      "Epoch [123/297], Loss: 0.3672\n",
      "Epoch [124/297], Loss: 0.3656\n",
      "Epoch [125/297], Loss: 0.3640\n",
      "Epoch [126/297], Loss: 0.3625\n",
      "Epoch [127/297], Loss: 0.3610\n",
      "Epoch [128/297], Loss: 0.3596\n",
      "Epoch [129/297], Loss: 0.3582\n",
      "Epoch [130/297], Loss: 0.3568\n",
      "Epoch [131/297], Loss: 0.3555\n",
      "Epoch [132/297], Loss: 0.3542\n",
      "Epoch [133/297], Loss: 0.3530\n",
      "Epoch [134/297], Loss: 0.3518\n",
      "Epoch [135/297], Loss: 0.3506\n",
      "Epoch [136/297], Loss: 0.3495\n",
      "Epoch [137/297], Loss: 0.3484\n",
      "Epoch [138/297], Loss: 0.3473\n",
      "Epoch [139/297], Loss: 0.3463\n",
      "Epoch [140/297], Loss: 0.3453\n",
      "Epoch [141/297], Loss: 0.3443\n",
      "Epoch [142/297], Loss: 0.3434\n",
      "Epoch [143/297], Loss: 0.3424\n",
      "Epoch [144/297], Loss: 0.3415\n",
      "Epoch [145/297], Loss: 0.3407\n",
      "Epoch [146/297], Loss: 0.3398\n",
      "Epoch [147/297], Loss: 0.3390\n",
      "Epoch [148/297], Loss: 0.3382\n",
      "Epoch [149/297], Loss: 0.3374\n",
      "Epoch [150/297], Loss: 0.3366\n",
      "Epoch [151/297], Loss: 0.3359\n",
      "Epoch [152/297], Loss: 0.3352\n",
      "Epoch [153/297], Loss: 0.3345\n",
      "Epoch [154/297], Loss: 0.3338\n",
      "Epoch [155/297], Loss: 0.3331\n",
      "Epoch [156/297], Loss: 0.3325\n",
      "Epoch [157/297], Loss: 0.3319\n",
      "Epoch [158/297], Loss: 0.3313\n",
      "Epoch [159/297], Loss: 0.3307\n",
      "Epoch [160/297], Loss: 0.3301\n",
      "Epoch [161/297], Loss: 0.3295\n",
      "Epoch [162/297], Loss: 0.3290\n",
      "Epoch [163/297], Loss: 0.3284\n",
      "Epoch [164/297], Loss: 0.3279\n",
      "Epoch [165/297], Loss: 0.3274\n",
      "Epoch [166/297], Loss: 0.3269\n",
      "Epoch [167/297], Loss: 0.3264\n",
      "Epoch [168/297], Loss: 0.3259\n",
      "Epoch [169/297], Loss: 0.3254\n",
      "Epoch [170/297], Loss: 0.3250\n",
      "Epoch [171/297], Loss: 0.3245\n",
      "Epoch [172/297], Loss: 0.3241\n",
      "Epoch [173/297], Loss: 0.3237\n",
      "Epoch [174/297], Loss: 0.3233\n",
      "Epoch [175/297], Loss: 0.3229\n",
      "Epoch [176/297], Loss: 0.3225\n",
      "Epoch [177/297], Loss: 0.3221\n",
      "Epoch [178/297], Loss: 0.3217\n",
      "Epoch [179/297], Loss: 0.3213\n",
      "Epoch [180/297], Loss: 0.3210\n",
      "Epoch [181/297], Loss: 0.3206\n",
      "Epoch [182/297], Loss: 0.3202\n",
      "Epoch [183/297], Loss: 0.3199\n",
      "Epoch [184/297], Loss: 0.3196\n",
      "Epoch [185/297], Loss: 0.3192\n",
      "Epoch [186/297], Loss: 0.3189\n",
      "Epoch [187/297], Loss: 0.3186\n",
      "Epoch [188/297], Loss: 0.3183\n",
      "Epoch [189/297], Loss: 0.3180\n",
      "Epoch [190/297], Loss: 0.3177\n",
      "Epoch [191/297], Loss: 0.3174\n",
      "Epoch [192/297], Loss: 0.3171\n",
      "Epoch [193/297], Loss: 0.3168\n",
      "Epoch [194/297], Loss: 0.3166\n",
      "Epoch [195/297], Loss: 0.3163\n",
      "Epoch [196/297], Loss: 0.3160\n",
      "Epoch [197/297], Loss: 0.3158\n",
      "Epoch [198/297], Loss: 0.3155\n",
      "Epoch [199/297], Loss: 0.3153\n",
      "Epoch [200/297], Loss: 0.3150\n",
      "Epoch [201/297], Loss: 0.3148\n",
      "Epoch [202/297], Loss: 0.3146\n",
      "Epoch [203/297], Loss: 0.3143\n",
      "Epoch [204/297], Loss: 0.3141\n",
      "Epoch [205/297], Loss: 0.3139\n",
      "Epoch [206/297], Loss: 0.3137\n",
      "Epoch [207/297], Loss: 0.3134\n",
      "Epoch [208/297], Loss: 0.3132\n",
      "Epoch [209/297], Loss: 0.3130\n",
      "Epoch [210/297], Loss: 0.3128\n",
      "Epoch [211/297], Loss: 0.3126\n",
      "Epoch [212/297], Loss: 0.3124\n",
      "Epoch [213/297], Loss: 0.3122\n",
      "Epoch [214/297], Loss: 0.3120\n",
      "Epoch [215/297], Loss: 0.3119\n",
      "Epoch [216/297], Loss: 0.3117\n",
      "Epoch [217/297], Loss: 0.3115\n",
      "Epoch [218/297], Loss: 0.3113\n",
      "Epoch [219/297], Loss: 0.3111\n",
      "Epoch [220/297], Loss: 0.3110\n",
      "Epoch [221/297], Loss: 0.3108\n",
      "Epoch [222/297], Loss: 0.3106\n",
      "Epoch [223/297], Loss: 0.3105\n",
      "Epoch [224/297], Loss: 0.3103\n",
      "Epoch [225/297], Loss: 0.3101\n",
      "Epoch [226/297], Loss: 0.3100\n",
      "Epoch [227/297], Loss: 0.3098\n",
      "Epoch [228/297], Loss: 0.3097\n",
      "Epoch [229/297], Loss: 0.3095\n",
      "Epoch [230/297], Loss: 0.3094\n",
      "Epoch [231/297], Loss: 0.3092\n",
      "Epoch [232/297], Loss: 0.3091\n",
      "Epoch [233/297], Loss: 0.3090\n",
      "Epoch [234/297], Loss: 0.3088\n",
      "Epoch [235/297], Loss: 0.3087\n",
      "Epoch [236/297], Loss: 0.3085\n",
      "Epoch [237/297], Loss: 0.3084\n",
      "Epoch [238/297], Loss: 0.3083\n",
      "Epoch [239/297], Loss: 0.3081\n",
      "Epoch [240/297], Loss: 0.3080\n",
      "Epoch [241/297], Loss: 0.3079\n",
      "Epoch [242/297], Loss: 0.3078\n",
      "Epoch [243/297], Loss: 0.3076\n",
      "Epoch [244/297], Loss: 0.3075\n",
      "Epoch [245/297], Loss: 0.3074\n",
      "Epoch [246/297], Loss: 0.3073\n",
      "Epoch [247/297], Loss: 0.3072\n",
      "Epoch [248/297], Loss: 0.3071\n",
      "Epoch [249/297], Loss: 0.3069\n",
      "Epoch [250/297], Loss: 0.3068\n",
      "Epoch [251/297], Loss: 0.3067\n",
      "Epoch [252/297], Loss: 0.3066\n",
      "Epoch [253/297], Loss: 0.3065\n",
      "Epoch [254/297], Loss: 0.3064\n",
      "Epoch [255/297], Loss: 0.3063\n",
      "Epoch [256/297], Loss: 0.3062\n",
      "Epoch [257/297], Loss: 0.3061\n",
      "Epoch [258/297], Loss: 0.3060\n",
      "Epoch [259/297], Loss: 0.3059\n",
      "Epoch [260/297], Loss: 0.3058\n",
      "Epoch [261/297], Loss: 0.3057\n",
      "Epoch [262/297], Loss: 0.3056\n",
      "Epoch [263/297], Loss: 0.3055\n",
      "Epoch [264/297], Loss: 0.3054\n",
      "Epoch [265/297], Loss: 0.3053\n",
      "Epoch [266/297], Loss: 0.3052\n",
      "Epoch [267/297], Loss: 0.3052\n",
      "Epoch [268/297], Loss: 0.3051\n",
      "Epoch [269/297], Loss: 0.3050\n",
      "Epoch [270/297], Loss: 0.3049\n",
      "Epoch [271/297], Loss: 0.3048\n",
      "Epoch [272/297], Loss: 0.3047\n",
      "Epoch [273/297], Loss: 0.3046\n",
      "Epoch [274/297], Loss: 0.3046\n",
      "Epoch [275/297], Loss: 0.3045\n",
      "Epoch [276/297], Loss: 0.3044\n",
      "Epoch [277/297], Loss: 0.3043\n",
      "Epoch [278/297], Loss: 0.3042\n",
      "Epoch [279/297], Loss: 0.3042\n",
      "Epoch [280/297], Loss: 0.3041\n",
      "Epoch [281/297], Loss: 0.3040\n",
      "Epoch [282/297], Loss: 0.3039\n",
      "Epoch [283/297], Loss: 0.3039\n",
      "Epoch [284/297], Loss: 0.3038\n",
      "Epoch [285/297], Loss: 0.3037\n",
      "Epoch [286/297], Loss: 0.3036\n",
      "Epoch [287/297], Loss: 0.3036\n",
      "Epoch [288/297], Loss: 0.3035\n",
      "Epoch [289/297], Loss: 0.3034\n",
      "Epoch [290/297], Loss: 0.3034\n",
      "Epoch [291/297], Loss: 0.3033\n",
      "Epoch [292/297], Loss: 0.3032\n",
      "Epoch [293/297], Loss: 0.3031\n",
      "Epoch [294/297], Loss: 0.3031\n",
      "Epoch [295/297], Loss: 0.3030\n",
      "Epoch [296/297], Loss: 0.3029\n",
      "Epoch [297/297], Loss: 0.3029\n"
     ]
    }
   ],
   "source": [
    "# Definisikan loss function dan optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Konversi data ke Tensor dan pindahkan ke perangkat yang digunakan\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Melatih model\n",
    "num_epochs = 297\n",
    "batch_size = 64\n",
    "num_samples = X_tensor.shape[0]\n",
    "num_batches = num_samples // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in range(num_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = (batch + 1) * batch_size\n",
    "        \n",
    "        inputs = X_tensor[start_idx:end_idx]\n",
    "        labels = y_tensor[start_idx:end_idx]\n",
    "        \n",
    "        # Melakukan forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Melakukan backward pass dan pembaruan bobot\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Mencetak loss pada setiap epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8c9bae-139e-4fe4-8124-8c5a0b934819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8552\n",
      "Precision: 0.8917\n",
      "Recall: 0.7810\n",
      "F1-score: 0.8327\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mengkonversi data pengujian ke Tensor dan memindahkannya ke perangkat yang digunakan\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Menjadikan model ke mode evaluasi (tidak ada pembaruan bobot)\n",
    "model.eval()\n",
    "\n",
    "# Melakukan prediksi pada data pengujian\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted_labels = (outputs >= 0.5).float()  # Menggunakan threshold 0.5 untuk klasifikasi biner\n",
    "\n",
    "# Menghitung metrik evaluasi\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels.cpu())\n",
    "precision = precision_score(y_test, predicted_labels.cpu())\n",
    "recall = recall_score(y_test, predicted_labels.cpu())\n",
    "f1 = f1_score(y_test, predicted_labels.cpu())\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f680448-d90b-4ff8-a8f5-afa011597144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#menyimpan hasil training\n",
    "torch.save(model.state_dict(), 'asep1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfd605-4cfb-4a2b-9000-f1accef8f454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02670f-67aa-4d2a-8517-97b5df696935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
